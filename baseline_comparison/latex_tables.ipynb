{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import itertools\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('agg_time_results_fbp_coop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['model_name'] = df['model_name'].replace('tars_xmt_final_sum', 'txmt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>split_type</th>\n",
       "      <th>max_days</th>\n",
       "      <th>pred_length</th>\n",
       "      <th>avg_f1_score</th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>avg_recall</th>\n",
       "      <th>avg_hit_score</th>\n",
       "      <th>avg_training_time_seconds</th>\n",
       "      <th>avg_pred_time_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.095092</td>\n",
       "      <td>0.403906</td>\n",
       "      <td>0.054511</td>\n",
       "      <td>0.646001</td>\n",
       "      <td>0.098021</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>top</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.131970</td>\n",
       "      <td>0.396776</td>\n",
       "      <td>0.080422</td>\n",
       "      <td>0.781773</td>\n",
       "      <td>0.098021</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>top</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.158209</td>\n",
       "      <td>0.379727</td>\n",
       "      <td>0.101963</td>\n",
       "      <td>0.838190</td>\n",
       "      <td>0.098021</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>top</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.183876</td>\n",
       "      <td>0.373094</td>\n",
       "      <td>0.124989</td>\n",
       "      <td>0.890267</td>\n",
       "      <td>0.098021</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>top</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.207522</td>\n",
       "      <td>0.369085</td>\n",
       "      <td>0.148404</td>\n",
       "      <td>0.921265</td>\n",
       "      <td>0.098021</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  split_type  max_days  pred_length  avg_f1_score  avg_precision  \\\n",
       "0        top          10         0            2      0.095092       0.403906   \n",
       "1        top          10         0            3      0.131970       0.396776   \n",
       "2        top          10         0            4      0.158209       0.379727   \n",
       "3        top          10         0            5      0.183876       0.373094   \n",
       "4        top          10         0            6      0.207522       0.369085   \n",
       "\n",
       "   avg_recall  avg_hit_score  avg_training_time_seconds  avg_pred_time_seconds  \n",
       "0    0.054511       0.646001                   0.098021               0.000015  \n",
       "1    0.080422       0.781773                   0.098021               0.000008  \n",
       "2    0.101963       0.838190                   0.098021               0.000007  \n",
       "3    0.124989       0.890267                   0.098021               0.000007  \n",
       "4    0.148404       0.921265                   0.098021               0.000007  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_latex_table(df, split_type, pred_lengths, metric):\n",
    "    \"\"\"\n",
    "    Generate a LaTeX table comparing model performances across different prediction lengths and max_days.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input dataframe\n",
    "    split_type (int): Split type to filter for (10, 20, ..., 90)\n",
    "    pred_lengths (list): List of prediction lengths to include\n",
    "    metric (str): Metric to compare ('f1_score', 'precision', or 'recall')\n",
    "    \"\"\"\n",
    "    # Map metric names to DataFrame columns\n",
    "    metric_map = {\n",
    "        'f1_score': 'avg_f1_score',\n",
    "        'precision': 'avg_precision',\n",
    "        'recall': 'avg_recall'\n",
    "    }\n",
    "    \n",
    "    # Filter data\n",
    "    filtered_df = df[df['split_type'] == split_type]\n",
    "    filtered_df = filtered_df[filtered_df['pred_length'].isin(pred_lengths)]\n",
    "    \n",
    "    # Get unique model names\n",
    "    models = sorted(filtered_df['model_name'].unique())\n",
    "    \n",
    "    # Create table rows\n",
    "    table_rows = []\n",
    "    \n",
    "    # Generate rows for each prediction length and max_days combination\n",
    "    for k in sorted(pred_lengths):\n",
    "        for max_day in [0, 1, 2]:\n",
    "            # Get data for this combination\n",
    "            condition_data = filtered_df[\n",
    "                (filtered_df['pred_length'] == k) & \n",
    "                (filtered_df['max_days'] == max_day)\n",
    "            ]\n",
    "            \n",
    "            # Create row header\n",
    "            if max_day == 0:\n",
    "                row_header = f'k={int(k)}'\n",
    "            else:\n",
    "                row_header = ''\n",
    "            \n",
    "            # Add max_days information\n",
    "            row = [row_header, f'd={max_day}']\n",
    "            \n",
    "            # Get all values for this row to determine the maximum\n",
    "            row_values = []\n",
    "            for model in models:\n",
    "                value = condition_data[condition_data['model_name'] == model][metric_map[metric]].values\n",
    "                if len(value) > 0:\n",
    "                    row_values.append(value[0])\n",
    "                else:\n",
    "                    row_values.append(float('-inf'))\n",
    "            \n",
    "            row_max = max(row_values)\n",
    "            \n",
    "            # Add values for each model\n",
    "            for i, model in enumerate(models):\n",
    "                value = condition_data[condition_data['model_name'] == model][metric_map[metric]].values\n",
    "                if len(value) > 0:\n",
    "                    formatted_value = f'{value[0]:.3f}'\n",
    "                    if abs(value[0] - row_max) < 1e-10:\n",
    "                        formatted_value = f'\\\\textbf{{{formatted_value}}}'\n",
    "                else:\n",
    "                    formatted_value = '-'\n",
    "                row.append(formatted_value)\n",
    "            \n",
    "            table_rows.append(' & '.join(row) + r' \\\\')\n",
    "            \n",
    "            # Add \\cline after each pred_length group, now starting from column 1\n",
    "            if max_day == 2:\n",
    "                table_rows.append('\\\\cline{1-' + str(len(models) + 2) + '}')\n",
    "    \n",
    "    # Create column specification with smaller column spacing\n",
    "    col_spec = r'@{}l@{\\hspace{4pt}}|@{\\hspace{4pt}}l|' + r'@{\\hspace{4pt}}c@{\\hspace{4pt}}' * len(models) + r'@{}'\n",
    "    \n",
    "    # Create header rows with split type and model names\n",
    "    split_type_header = f'\\\\multicolumn{{{len(models) + 2}}}{{c}}{{Split Type = {split_type}\\\\%}} \\\\\\\\'\n",
    "    model_header = '& & ' + ' & '.join(models) + r' \\\\'\n",
    "    \n",
    "    # Create the LaTeX table with smaller font and tighter spacing\n",
    "    latex_table = f\"\"\"\\\\begin{{table}}[h]\n",
    "\\\\centering\n",
    "\\\\small\n",
    "\\\\setlength{{\\\\tabcolsep}}{{4pt}}\n",
    "\\\\begin{{tabular}}{{{col_spec}}}\n",
    "\\\\hline\n",
    "{split_type_header}\n",
    "\\\\hline\n",
    "{model_header}\n",
    "\\\\hline\n",
    "{chr(10).join(table_rows)}\n",
    "\\\\hline\n",
    "\\\\end{{tabular}}\n",
    "\\\\caption{{{metric.replace('_', ' ').title()} comparison for different prediction lengths (k) and days (d)}}\n",
    "\\\\label{{tab:comparison_{metric}_{split_type}}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "    \n",
    "    # Save to file\n",
    "    filename = f'table_{metric}_{split_type}.tex'\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(latex_table)\n",
    "    \n",
    "    print(f\"Table saved to {filename}\")\n",
    "    return latex_table\n",
    "\n",
    "# Example usage:\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "# generate_latex_table(df, split_type=90, pred_lengths=[5.0, 10.0, 15.0, 20.0], metric='f1_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table saved to table_f1_score_70.tex\n",
      "Table saved to table_recall_70.tex\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\\\begin{table}[h]\\n\\\\centering\\n\\\\small\\n\\\\setlength{\\\\tabcolsep}{4pt}\\n\\\\begin{tabular}{@{}l@{\\\\hspace{4pt}}|@{\\\\hspace{4pt}}l|@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{}}\\n\\\\hline\\n\\\\multicolumn{13}{c}{Split Type = 70\\\\%} \\\\\\\\\\n\\\\hline\\n& & clf & fpmc & hrm & ibp & last & markov & nmf & tbp & top & txmt & xmt \\\\\\\\\\n\\\\hline\\nk=5 & d=0 & 0.095 & 0.018 & 0.110 & 0.094 & 0.035 & 0.123 & 0.126 & 0.125 & 0.124 & \\\\textbf{0.170} & 0.168 \\\\\\\\\\n & d=1 & 0.095 & 0.015 & 0.085 & 0.085 & 0.037 & 0.125 & 0.122 & 0.124 & 0.124 & \\\\textbf{0.159} & 0.155 \\\\\\\\\\n & d=2 & 0.094 & 0.015 & 0.079 & 0.083 & 0.037 & 0.123 & 0.123 & 0.123 & 0.123 & \\\\textbf{0.157} & 0.153 \\\\\\\\\\n\\\\cline{1-13}\\nk=10 & d=0 & 0.168 & 0.035 & 0.192 & 0.157 & 0.035 & 0.227 & 0.228 & 0.219 & 0.224 & \\\\textbf{0.275} & 0.268 \\\\\\\\\\n & d=1 & 0.170 & 0.030 & 0.166 & 0.146 & 0.037 & 0.221 & 0.218 & 0.221 & 0.221 & \\\\textbf{0.261} & 0.256 \\\\\\\\\\n & d=2 & 0.169 & 0.030 & 0.153 & 0.141 & 0.037 & 0.220 & 0.220 & 0.219 & 0.220 & \\\\textbf{0.258} & 0.253 \\\\\\\\\\n\\\\cline{1-13}\\nk=15 & d=0 & 0.232 & 0.052 & 0.269 & 0.203 & 0.035 & 0.311 & 0.305 & 0.306 & 0.306 & \\\\textbf{0.357} & 0.347 \\\\\\\\\\n & d=1 & 0.233 & 0.044 & 0.240 & 0.191 & 0.037 & 0.304 & 0.303 & 0.299 & 0.304 & \\\\textbf{0.339} & 0.335 \\\\\\\\\\n & d=2 & 0.232 & 0.045 & 0.224 & 0.184 & 0.037 & 0.298 & 0.300 & 0.294 & 0.299 & \\\\textbf{0.334} & 0.331 \\\\\\\\\\n\\\\cline{1-13}\\nk=20 & d=0 & 0.290 & 0.070 & 0.332 & 0.244 & 0.035 & 0.382 & 0.376 & 0.371 & 0.381 & \\\\textbf{0.419} & 0.414 \\\\\\\\\\n & d=1 & 0.287 & 0.060 & 0.307 & 0.226 & 0.037 & 0.373 & 0.371 & 0.362 & 0.374 & \\\\textbf{0.401} & 0.398 \\\\\\\\\\n & d=2 & 0.286 & 0.060 & 0.292 & 0.218 & 0.037 & 0.366 & 0.369 & 0.355 & 0.368 & \\\\textbf{0.394} & 0.391 \\\\\\\\\\n\\\\cline{1-13}\\n\\\\hline\\n\\\\end{tabular}\\n\\\\caption{Recall comparison for different prediction lengths (k) and days (d)}\\n\\\\label{tab:comparison_recall_70}\\n\\\\end{table}\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage:\n",
    "\n",
    "generate_latex_table(\n",
    "    df=df,\n",
    "    split_type=70,\n",
    "    pred_lengths=[5.0, 10.0, 15.0, 20.0],\n",
    "    metric='f1_score'\n",
    ")\n",
    "\n",
    "generate_latex_table(\n",
    "    df=df,\n",
    "    split_type=70,\n",
    "    pred_lengths=[5.0, 10.0, 15.0, 20.0],\n",
    "    metric='recall'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table saved to table_time_training_time_70.tex\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\\\begin{table}[h]\\n\\\\centering\\n\\\\small\\n\\\\setlength{\\\\tabcolsep}{4pt}\\n\\\\begin{tabular}{@{}l@{\\\\hspace{4pt}}|@{\\\\hspace{4pt}}l|@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{}}\\n\\\\hline\\n\\\\multicolumn{13}{c}{Split Type = 70\\\\%} \\\\\\\\\\n\\\\hline\\n& & clf & fpmc & hrm & ibp & last & markov & nmf & tbp & top & txmt & xmt \\\\\\\\\\n\\\\hline\\nk=5 & d=0 & 19.197 & 0.362 & 150.771 & 0.198 & \\\\textbf{0.044} & 0.220 & 0.357 & 9.460 & 0.051 & 595.684 & 0.653 \\\\\\\\\\n & d=1 & 154.077 & 3.350 & 2046.357 & 1.538 & \\\\textbf{0.505} & 2.284 & 42.659 & 8.820 & 0.535 & 2197.969 & 5.852 \\\\\\\\\\n & d=2 & 188.839 & 3.416 & 2434.319 & 1.753 & \\\\textbf{0.530} & 3.105 & 47.549 & 7.585 & 0.568 & 3486.571 & 6.713 \\\\\\\\\\n\\\\cline{1-13}\\nk=10 & d=0 & 19.197 & 0.362 & 150.771 & 0.198 & \\\\textbf{0.044} & 0.220 & 0.357 & 9.460 & 0.051 & 595.684 & 0.653 \\\\\\\\\\n & d=1 & 154.077 & 3.350 & 2046.357 & 1.538 & \\\\textbf{0.505} & 2.284 & 42.659 & 8.820 & 0.535 & 2197.969 & 5.852 \\\\\\\\\\n & d=2 & 188.839 & 3.416 & 2434.319 & 1.753 & \\\\textbf{0.530} & 3.105 & 47.549 & 7.585 & 0.568 & 3486.571 & 6.713 \\\\\\\\\\n\\\\cline{1-13}\\nk=15 & d=0 & 19.197 & 0.362 & 150.771 & 0.198 & \\\\textbf{0.044} & 0.220 & 0.357 & 9.460 & 0.051 & 595.684 & 0.653 \\\\\\\\\\n & d=1 & 154.077 & 3.350 & 2046.357 & 1.538 & \\\\textbf{0.505} & 2.284 & 42.659 & 8.820 & 0.535 & 2197.969 & 5.852 \\\\\\\\\\n & d=2 & 188.839 & 3.416 & 2434.319 & 1.753 & \\\\textbf{0.530} & 3.105 & 47.549 & 7.585 & 0.568 & 3486.571 & 6.713 \\\\\\\\\\n\\\\cline{1-13}\\nk=20 & d=0 & 19.197 & 0.362 & 150.771 & 0.198 & \\\\textbf{0.044} & 0.220 & 0.357 & 9.460 & 0.051 & 595.684 & 0.653 \\\\\\\\\\n & d=1 & 154.077 & 3.350 & 2046.357 & 1.538 & \\\\textbf{0.505} & 2.284 & 42.659 & 8.820 & 0.535 & 2197.969 & 5.852 \\\\\\\\\\n & d=2 & 188.839 & 3.416 & 2434.319 & 1.753 & \\\\textbf{0.530} & 3.105 & 47.549 & 7.585 & 0.568 & 3486.571 & 6.713 \\\\\\\\\\n\\\\cline{1-13}\\n\\\\hline\\n\\\\end{tabular}\\n\\\\caption{Training Time (in seconds) comparison for different prediction lengths (k) and days (d)}\\n\\\\label{tab:comparison_time_training_time_70}\\n\\\\end{table}\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_latex_table(df, split_type, pred_lengths, metric_type='performance', metric='f1_score'):\n",
    "    \"\"\"\n",
    "    Generate a LaTeX table comparing model performances or timing metrics across different prediction lengths and max_days.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input dataframe\n",
    "    split_type (int): Split type to filter for (10, 20, ..., 90)\n",
    "    pred_lengths (list): List of prediction lengths to include\n",
    "    metric_type (str): Type of metric to compare ('performance' or 'time')\n",
    "    metric (str): Specific metric to compare:\n",
    "        - If metric_type='performance': 'f1_score', 'precision', or 'recall'\n",
    "        - If metric_type='time': 'training_time' or 'pred_time'\n",
    "    \"\"\"\n",
    "    # Map metric names to DataFrame columns\n",
    "    performance_metrics = {\n",
    "        'f1_score': 'avg_f1_score',\n",
    "        'precision': 'avg_precision',\n",
    "        'recall': 'avg_recall'\n",
    "    }\n",
    "    \n",
    "    time_metrics = {\n",
    "        'training_time': 'avg_training_time_seconds',\n",
    "        'pred_time': 'avg_pred_time_seconds'\n",
    "    }\n",
    "    \n",
    "    # Select appropriate metric mapping\n",
    "    metric_map = time_metrics if metric_type == 'time' else performance_metrics\n",
    "    if metric not in metric_map:\n",
    "        raise ValueError(f\"Invalid metric '{metric}' for metric_type '{metric_type}'\")\n",
    "    \n",
    "    # Filter data\n",
    "    filtered_df = df[df['split_type'] == split_type]\n",
    "    filtered_df = filtered_df[filtered_df['pred_length'].isin(pred_lengths)]\n",
    "    \n",
    "    # Get unique model names\n",
    "    models = sorted(filtered_df['model_name'].unique())\n",
    "    \n",
    "    # Create table rows\n",
    "    table_rows = []\n",
    "    \n",
    "    # Generate rows for each prediction length and max_days combination\n",
    "    for k in sorted(pred_lengths):\n",
    "        for max_day in [0, 1, 2]:\n",
    "            # Get data for this combination\n",
    "            condition_data = filtered_df[\n",
    "                (filtered_df['pred_length'] == k) & \n",
    "                (filtered_df['max_days'] == max_day)\n",
    "            ]\n",
    "            \n",
    "            # Create row header\n",
    "            if max_day == 0:\n",
    "                row_header = f'k={int(k)}'\n",
    "            else:\n",
    "                row_header = ''\n",
    "            \n",
    "            # Add max_days information\n",
    "            row = [row_header, f'd={max_day}']\n",
    "            \n",
    "            # Get all values for this row to determine the minimum (for time metrics) or maximum (for performance metrics)\n",
    "            row_values = []\n",
    "            for model in models:\n",
    "                value = condition_data[condition_data['model_name'] == model][metric_map[metric]].values\n",
    "                if len(value) > 0:\n",
    "                    row_values.append(value[0])\n",
    "                else:\n",
    "                    row_values.append(float('inf') if metric_type == 'time' else float('-inf'))\n",
    "            \n",
    "            # For time metrics, we want to highlight the minimum value\n",
    "            # For performance metrics, we want to highlight the maximum value\n",
    "            row_best = min(row_values) if metric_type == 'time' else max(row_values)\n",
    "            \n",
    "            # Add values for each model\n",
    "            for i, model in enumerate(models):\n",
    "                value = condition_data[condition_data['model_name'] == model][metric_map[metric]].values\n",
    "                if len(value) > 0:\n",
    "                    # Format time values differently\n",
    "                    if metric_type == 'time':\n",
    "                        formatted_value = f'{value[0]:.3f}'\n",
    "                        if abs(value[0] - row_best) < 1e-10:\n",
    "                            formatted_value = f'\\\\textbf{{{formatted_value}}}'\n",
    "                    else:\n",
    "                        formatted_value = f'{value[0]:.3f}'\n",
    "                        if abs(value[0] - row_best) < 1e-10:\n",
    "                            formatted_value = f'\\\\textbf{{{formatted_value}}}'\n",
    "                else:\n",
    "                    formatted_value = '-'\n",
    "                row.append(formatted_value)\n",
    "            \n",
    "            table_rows.append(' & '.join(row) + r' \\\\')\n",
    "            \n",
    "            # Add \\cline after each pred_length group\n",
    "            if max_day == 2:\n",
    "                table_rows.append('\\\\cline{1-' + str(len(models) + 2) + '}')\n",
    "    \n",
    "    # Create column specification with smaller column spacing\n",
    "    col_spec = r'@{}l@{\\hspace{4pt}}|@{\\hspace{4pt}}l|' + r'@{\\hspace{4pt}}c@{\\hspace{4pt}}' * len(models) + r'@{}'\n",
    "    \n",
    "    # Create header rows with split type and model names\n",
    "    split_type_header = f'\\\\multicolumn{{{len(models) + 2}}}{{c}}{{Split Type = {split_type}\\\\%}} \\\\\\\\'\n",
    "    model_header = '& & ' + ' & '.join(models) + r' \\\\'\n",
    "    \n",
    "    # Create metric description for caption\n",
    "    if metric_type == 'time':\n",
    "        metric_desc = 'Training Time' if metric == 'training_time' else 'Prediction Time'\n",
    "        metric_desc += ' (in seconds)'\n",
    "    else:\n",
    "        metric_desc = metric.replace('_', ' ').title()\n",
    "    \n",
    "    # Create the LaTeX table with smaller font and tighter spacing\n",
    "    latex_table = f\"\"\"\\\\begin{{table}}[h]\n",
    "\\\\centering\n",
    "\\\\small\n",
    "\\\\setlength{{\\\\tabcolsep}}{{4pt}}\n",
    "\\\\begin{{tabular}}{{{col_spec}}}\n",
    "\\\\hline\n",
    "{split_type_header}\n",
    "\\\\hline\n",
    "{model_header}\n",
    "\\\\hline\n",
    "{chr(10).join(table_rows)}\n",
    "\\\\hline\n",
    "\\\\end{{tabular}}\n",
    "\\\\caption{{{metric_desc} comparison for different prediction lengths (k) and days (d)}}\n",
    "\\\\label{{tab:comparison_{metric_type}_{metric}_{split_type}}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "    \n",
    "    # Save to file\n",
    "    filename = f'table_{metric_type}_{metric}_{split_type}.tex'\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(latex_table)\n",
    "    \n",
    "    print(f\"Table saved to {filename}\")\n",
    "    return latex_table\n",
    "\n",
    "# Example usage:\n",
    "df = df\n",
    "# # For performance metrics:\n",
    "# generate_latex_table(df, split_type=90, pred_lengths=[5.0, 10.0, 15.0, 20.0], metric_type='performance', metric='f1_score')\n",
    "# # For timing metrics:\n",
    "generate_latex_table(df, split_type=70, pred_lengths=[5.0, 10.0, 15.0, 20.0], metric_type='time', metric='training_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table saved to table_time_pred_time_70.tex\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\\\begin{table}[h]\\n\\\\centering\\n\\\\small\\n\\\\setlength{\\\\tabcolsep}{4pt}\\n\\\\begin{tabular}{@{}l@{\\\\hspace{4pt}}|@{\\\\hspace{4pt}}l|@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{\\\\hspace{4pt}}c@{\\\\hspace{4pt}}@{}}\\n\\\\hline\\n\\\\multicolumn{13}{c}{Split Type = 70\\\\%} \\\\\\\\\\n\\\\hline\\n& & clf & fpmc & hrm & ibp & last & markov & nmf & tbp & top & txmt & xmt \\\\\\\\\\n\\\\hline\\nk=5 & d=0 & 0.004 & 0.000 & 0.000 & 0.000 & \\\\textbf{0.000} & 0.000 & 0.000 & 0.113 & 0.000 & 0.000 & 0.000 \\\\\\\\\\n & d=1 & 0.004 & 0.000 & 0.000 & 0.000 & \\\\textbf{0.000} & 0.000 & 0.000 & 0.148 & 0.000 & 0.000 & 0.000 \\\\\\\\\\n & d=2 & 0.004 & 0.000 & 0.000 & 0.000 & \\\\textbf{0.000} & 0.000 & 0.000 & 0.141 & 0.000 & 0.000 & 0.000 \\\\\\\\\\n\\\\cline{1-13}\\nk=10 & d=0 & 0.004 & 0.000 & 0.000 & 0.000 & \\\\textbf{0.000} & 0.000 & 0.000 & 0.114 & 0.000 & 0.000 & 0.001 \\\\\\\\\\n & d=1 & 0.004 & 0.000 & 0.000 & 0.000 & \\\\textbf{0.000} & 0.000 & 0.000 & 0.146 & 0.000 & 0.000 & 0.000 \\\\\\\\\\n & d=2 & 0.004 & 0.000 & 0.000 & 0.000 & \\\\textbf{0.000} & 0.000 & 0.000 & 0.140 & 0.000 & 0.000 & 0.000 \\\\\\\\\\n\\\\cline{1-13}\\nk=15 & d=0 & 0.004 & 0.000 & 0.000 & 0.000 & \\\\textbf{0.000} & 0.000 & 0.000 & 0.111 & 0.000 & 0.000 & 0.001 \\\\\\\\\\n & d=1 & 0.004 & 0.000 & 0.000 & 0.000 & \\\\textbf{0.000} & 0.000 & 0.000 & 0.146 & 0.000 & 0.000 & 0.001 \\\\\\\\\\n & d=2 & 0.004 & 0.000 & 0.000 & 0.000 & \\\\textbf{0.000} & 0.000 & 0.000 & 0.140 & 0.000 & 0.000 & 0.001 \\\\\\\\\\n\\\\cline{1-13}\\nk=20 & d=0 & 0.004 & 0.000 & 0.000 & 0.000 & \\\\textbf{0.000} & 0.000 & 0.000 & 0.113 & 0.000 & 0.000 & 0.001 \\\\\\\\\\n & d=1 & 0.004 & 0.000 & 0.000 & 0.000 & \\\\textbf{0.000} & 0.000 & 0.000 & 0.147 & 0.000 & 0.000 & 0.001 \\\\\\\\\\n & d=2 & 0.004 & 0.000 & 0.000 & 0.000 & \\\\textbf{0.000} & 0.000 & 0.000 & 0.139 & 0.000 & 0.000 & 0.001 \\\\\\\\\\n\\\\cline{1-13}\\n\\\\hline\\n\\\\end{tabular}\\n\\\\caption{Prediction Time (in seconds) comparison for different prediction lengths (k) and days (d)}\\n\\\\label{tab:comparison_time_pred_time_70}\\n\\\\end{table}\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_latex_table(df, split_type=70, pred_lengths=[5.0, 10.0, 15.0, 20.0], metric_type='time', metric='pred_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
