{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many 'Forgotten items' baskets are the re in the coop_data.json dataset?\n",
    "\n",
    "#### Definition  of 'Forgotten items basket': a small basket with 'X' number of products (1-2) bought 'Y' number of days after a 'large' purchase of 'Z' amount of products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_shopping_history(file_path):\n",
    "    \"\"\"\n",
    "    Process a JSON file containing shopping history and return a structured DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Path to the JSON file where each line is a separate JSON object\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame with columns customer_id, transaction_date, and basket_content\n",
    "    \"\"\"\n",
    "    # Lists to store the extracted data\n",
    "    records = []\n",
    "    \n",
    "    # Read the file line by line\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.strip():  # Skip empty lines\n",
    "                # Parse JSON object\n",
    "                customer_data = json.loads(line)\n",
    "                customer_id = customer_data['customer_id']\n",
    "                \n",
    "                # Process each transaction date in the customer's data\n",
    "                for date_key, transaction in customer_data['data'].items():\n",
    "                    # Extract date from the key (format: YYYY_MM_DD_XX)\n",
    "                    date_parts = date_key.split('_')\n",
    "                    transaction_date = datetime(\n",
    "                        int(date_parts[0]),\n",
    "                        int(date_parts[1]),\n",
    "                        int(date_parts[2])\n",
    "                    )\n",
    "                    \n",
    "                    # Extract basket items (only IDs)\n",
    "                    basket_items = set(str(item_id) for item_id in transaction['basket'].keys())\n",
    "                    \n",
    "                    # Create a record\n",
    "                    records.append({\n",
    "                        'customer_id': customer_id,\n",
    "                        'transaction_date': transaction_date,\n",
    "                        'basket_content': basket_items\n",
    "                    })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    # Sort the DataFrame by customer_id and transaction_date\n",
    "    df_sorted = df.sort_values(['customer_id', 'transaction_date'])\n",
    "    \n",
    "    # Reset index after sorting\n",
    "    df_sorted = df_sorted.reset_index(drop=True)\n",
    "    \n",
    "    return df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"E:\\Thesis\\Legrottaglie Forgotten Items\\Model\\dataset\\Full dataset\\clean\\coop_data_clean.json\"\n",
    "\n",
    "\n",
    "# path = r\"E:\\Thesis\\Legrottaglie Forgotten Items\\Model\\dataset\\tafeng\\tafeng.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = process_shopping_history(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>basket_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67656</td>\n",
       "      <td>2007-01-02</td>\n",
       "      <td>{1830, 3226, 1826, 2134, 476, 505, 5082, 622}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67656</td>\n",
       "      <td>2007-01-08</td>\n",
       "      <td>{4436, 140, 642, 4831, 5069, 633, 1579, 1577, 4117, 5012, 657, 4196, 3607, 5028}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67656</td>\n",
       "      <td>2007-01-11</td>\n",
       "      <td>{2090, 2980, 140, 4031, 1261, 4003, 142, 2302, 2095, 2074}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67656</td>\n",
       "      <td>2007-01-17</td>\n",
       "      <td>{1012, 2038, 178, 140, 4626, 5945, 3143, 1870, 141, 2502, 234, 5082}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67656</td>\n",
       "      <td>2007-01-20</td>\n",
       "      <td>{1621, 140, 216, 1570, 1261, 1564, 1577, 1467, 4900, 142, 2551, 657, 1622, 1090, 891, 1989}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id transaction_date  \\\n",
       "0        67656       2007-01-02   \n",
       "1        67656       2007-01-08   \n",
       "2        67656       2007-01-11   \n",
       "3        67656       2007-01-17   \n",
       "4        67656       2007-01-20   \n",
       "\n",
       "                                                                                basket_content  \n",
       "0                                                {1830, 3226, 1826, 2134, 476, 505, 5082, 622}  \n",
       "1             {4436, 140, 642, 4831, 5069, 633, 1579, 1577, 4117, 5012, 657, 4196, 3607, 5028}  \n",
       "2                                   {2090, 2980, 140, 4031, 1261, 4003, 142, 2302, 2095, 2074}  \n",
       "3                         {1012, 2038, 178, 140, 4626, 5945, 3143, 1870, 141, 2502, 234, 5082}  \n",
       "4  {1621, 140, 216, 1570, 1261, 1564, 1577, 1467, 4900, 142, 2551, 657, 1622, 1090, 891, 1989}  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique items: 5552\n"
     ]
    }
   ],
   "source": [
    "def analyze_unique_items(df):\n",
    "    \"\"\"\n",
    "    Analyzes DataFrame containing basket content data and returns the number of unique items\n",
    "    across all baskets where basket contents are stored as sets.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame containing a column with basket contents as sets\n",
    "        \n",
    "    Returns:\n",
    "        int: Number of unique items across all baskets\n",
    "    \"\"\"\n",
    "    # Create a single set to store all unique items\n",
    "    all_unique_items = set()\n",
    "    \n",
    "    # Process each basket set\n",
    "    for basket_set in df['basket_content']:\n",
    "        # Update the all_unique_items set with items from current basket\n",
    "        all_unique_items.update(basket_set)\n",
    "    \n",
    "    return len(all_unique_items)\n",
    "\n",
    "# Example usage:\n",
    "total_unique_items = analyze_unique_items(df)\n",
    "print(f\"Total number of unique items: {total_unique_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10867976, 3)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by the first column and then by the second column\n",
    "# Sort by the first and second column, and reset the index\n",
    "df = df.sort_values(by=[df.columns[0], df.columns[1]]).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>basket_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67656</td>\n",
       "      <td>2007-01-02</td>\n",
       "      <td>{1830, 3226, 1826, 2134, 476, 505, 5082, 622}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67656</td>\n",
       "      <td>2007-01-08</td>\n",
       "      <td>{4436, 140, 642, 4831, 5069, 633, 1579, 1577, 4117, 5012, 657, 4196, 3607, 5028}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67656</td>\n",
       "      <td>2007-01-11</td>\n",
       "      <td>{2090, 2980, 140, 4031, 1261, 4003, 142, 2302, 2095, 2074}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67656</td>\n",
       "      <td>2007-01-17</td>\n",
       "      <td>{1012, 2038, 178, 140, 4626, 5945, 3143, 1870, 141, 2502, 234, 5082}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67656</td>\n",
       "      <td>2007-01-20</td>\n",
       "      <td>{1621, 140, 216, 1570, 1261, 1564, 1577, 1467, 4900, 142, 2551, 657, 1622, 1090, 891, 1989}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id transaction_date  \\\n",
       "0        67656       2007-01-02   \n",
       "1        67656       2007-01-08   \n",
       "2        67656       2007-01-11   \n",
       "3        67656       2007-01-17   \n",
       "4        67656       2007-01-20   \n",
       "\n",
       "                                                                                basket_content  \n",
       "0                                                {1830, 3226, 1826, 2134, 476, 505, 5082, 622}  \n",
       "1             {4436, 140, 642, 4831, 5069, 633, 1579, 1577, 4117, 5012, 657, 4196, 3607, 5028}  \n",
       "2                                   {2090, 2980, 140, 4031, 1261, 4003, 142, 2302, 2095, 2074}  \n",
       "3                         {1012, 2038, 178, 140, 4626, 5945, 3143, 1870, 141, 2502, 234, 5082}  \n",
       "4  {1621, 140, 216, 1570, 1261, 1564, 1577, 1467, 4900, 142, 2551, 657, 1622, 1090, 891, 1989}  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum date: 2007-01-02 00:00:00\n",
      "Maximum date: 2016-08-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Find the minimum and maximum values\n",
    "min_date = df['transaction_date'].min()\n",
    "max_date = df['transaction_date'].max()\n",
    "\n",
    "print(f\"Minimum date: {min_date}\")\n",
    "print(f\"Maximum date: {max_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10867976, 3)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17132"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['customer_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating avg, number of baskets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_baskets_per_customer(df):\n",
    "    \"\"\"\n",
    "    Calculate the average number of baskets (transactions) per customer.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing columns 'customer_id' and 'transaction_date'\n",
    "                         as created by process_shopping_history()\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary containing:\n",
    "          - 'avg_baskets': Average number of baskets per customer\n",
    "          - 'total_customers': Total number of unique customers\n",
    "          - 'total_baskets': Total number of baskets/transactions\n",
    "    \"\"\"\n",
    "    # Count number of transactions per customer\n",
    "    baskets_per_customer = df.groupby('customer_id').size()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    total_customers = len(baskets_per_customer)\n",
    "    total_baskets = baskets_per_customer.sum()\n",
    "    avg_baskets = total_baskets / total_customers\n",
    "    \n",
    "    return {\n",
    "        'avg_baskets': round(avg_baskets, 2),\n",
    "        'total_customers': total_customers,\n",
    "        'total_baskets': total_baskets\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average baskets per customer: 634.37\n",
      "Total customers: 17132\n",
      "Total baskets: 10867976\n"
     ]
    }
   ],
   "source": [
    "stats = calculate_avg_baskets_per_customer(df)\n",
    "\n",
    "print(f\"Average baskets per customer: {stats['avg_baskets']}\")\n",
    "print(f\"Total customers: {stats['total_customers']}\")\n",
    "print(f\"Total baskets: {stats['total_baskets']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating median number of baskets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_median_baskets_per_customer(df):\n",
    "    \"\"\"\n",
    "    Calculate the median number of baskets (transactions) per customer.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing columns 'customer_id' and 'transaction_date'\n",
    "                         as created by process_shopping_history()\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary containing:\n",
    "          - 'median_baskets': Median number of baskets per customer\n",
    "          - 'q1_baskets': First quartile (25th percentile) of baskets per customer\n",
    "          - 'q3_baskets': Third quartile (75th percentile) of baskets per customer\n",
    "          - 'total_customers': Total number of unique customers\n",
    "          - 'total_baskets': Total number of baskets/transactions\n",
    "          - 'min_baskets': Minimum number of baskets for any customer\n",
    "          - 'max_baskets': Maximum number of baskets for any customer\n",
    "    \"\"\"\n",
    "    # Count number of transactions per customer\n",
    "    baskets_per_customer = df.groupby('customer_id').size()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    total_customers = len(baskets_per_customer)\n",
    "    total_baskets = baskets_per_customer.sum()\n",
    "    \n",
    "    # Calculate quartile statistics\n",
    "    median_baskets = baskets_per_customer.median()\n",
    "    q1_baskets = baskets_per_customer.quantile(0.25)\n",
    "    q3_baskets = baskets_per_customer.quantile(0.75)\n",
    "    min_baskets = baskets_per_customer.min()\n",
    "    max_baskets = baskets_per_customer.max()\n",
    "    \n",
    "    # Calculate interquartile range (IQR)\n",
    "    iqr = q3_baskets - q1_baskets\n",
    "    \n",
    "    return {\n",
    "        'median_baskets': round(median_baskets, 2),\n",
    "        'q1_baskets': round(q1_baskets, 2),\n",
    "        'q3_baskets': round(q3_baskets, 2),\n",
    "        'total_customers': total_customers,\n",
    "        'total_baskets': total_baskets,\n",
    "        'min_baskets': min_baskets,\n",
    "        'max_baskets': max_baskets,\n",
    "        'iqr': round(iqr, 2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median baskets per customer: 452.0\n",
      "First quartile (25%): 220.75 baskets\n",
      "Third quartile (75%): 856.0 baskets\n",
      "Interquartile range: 635.25 baskets\n",
      "Range: 4 to 3696 baskets\n",
      "Total customers: 17132\n",
      "Total baskets: 10867976\n"
     ]
    }
   ],
   "source": [
    "# Calculate median baskets per customer\n",
    "stats = calculate_median_baskets_per_customer(df)\n",
    "\n",
    "print(f\"Median baskets per customer: {stats['median_baskets']}\")\n",
    "print(f\"First quartile (25%): {stats['q1_baskets']} baskets\")\n",
    "print(f\"Third quartile (75%): {stats['q3_baskets']} baskets\")\n",
    "print(f\"Interquartile range: {stats['iqr']} baskets\")\n",
    "print(f\"Range: {stats['min_baskets']} to {stats['max_baskets']} baskets\")\n",
    "print(f\"Total customers: {stats['total_customers']}\")\n",
    "print(f\"Total baskets: {stats['total_baskets']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate avg timespan between first and last purchase in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_customer_timespan(df):\n",
    "    \"\"\"\n",
    "    Calculate the average time span between first and last purchase for each customer.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing columns 'customer_id' and 'transaction_date'\n",
    "                         as created by process_shopping_history()\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary containing:\n",
    "          - 'avg_days': Average number of days between first and last purchase\n",
    "          - 'avg_months': Average number of months between first and last purchase\n",
    "          - 'total_active_customers': Number of customers with more than one purchase\n",
    "          - 'single_purchase_customers': Number of customers with only one purchase\n",
    "          - 'max_timespan_days': Longest customer timespan in days\n",
    "          - 'min_timespan_days': Shortest customer timespan in days (excluding single-purchase customers)\n",
    "    \"\"\"\n",
    "    # Group by customer and get their first and last purchase dates\n",
    "    customer_spans = df.groupby('customer_id').agg({\n",
    "        'transaction_date': ['min', 'max', 'count']\n",
    "    })\n",
    "    \n",
    "    # Flatten column names\n",
    "    customer_spans.columns = ['first_purchase', 'last_purchase', 'purchase_count']\n",
    "    \n",
    "    # Calculate time difference for each customer\n",
    "    customer_spans['timespan_days'] = (\n",
    "        customer_spans['last_purchase'] - customer_spans['first_purchase']\n",
    "    ).dt.total_seconds() / (24 * 60 * 60)  # Convert to days\n",
    "    \n",
    "    # Count customers with single purchase\n",
    "    single_purchase_customers = (customer_spans['purchase_count'] == 1).sum()\n",
    "    \n",
    "    # Filter for customers with more than one purchase for average calculation\n",
    "    multiple_purchase_spans = customer_spans[customer_spans['purchase_count'] > 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    if len(multiple_purchase_spans) > 0:\n",
    "        avg_days = multiple_purchase_spans['timespan_days'].mean()\n",
    "        avg_months = avg_days / 30.44  # Using average month length\n",
    "        max_timespan = multiple_purchase_spans['timespan_days'].max()\n",
    "        min_timespan = multiple_purchase_spans['timespan_days'].min()\n",
    "    else:\n",
    "        avg_days = 0\n",
    "        avg_months = 0\n",
    "        max_timespan = 0\n",
    "        min_timespan = 0\n",
    "    \n",
    "    return {\n",
    "        'avg_days': round(avg_days, 2),\n",
    "        'avg_months': round(avg_months, 2),\n",
    "        'total_active_customers': len(multiple_purchase_spans),\n",
    "        'single_purchase_customers': single_purchase_customers,\n",
    "        'max_timespan_days': round(max_timespan, 2),\n",
    "        'min_timespan_days': round(min_timespan, 2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average customer timespan: 3078.29 days (101.13 months)\n",
      "Active customers (>1 purchase): 17132\n",
      "Single-purchase customers: 0\n",
      "Longest customer timespan: 3529.0 days\n",
      "Shortest customer timespan: 9.0 days\n"
     ]
    }
   ],
   "source": [
    "# Calculate average customer timespan\n",
    "timespan_stats = calculate_avg_customer_timespan(df)\n",
    "\n",
    "print(f\"Average customer timespan: {timespan_stats['avg_days']} days ({timespan_stats['avg_months']} months)\")\n",
    "print(f\"Active customers (>1 purchase): {timespan_stats['total_active_customers']}\")\n",
    "print(f\"Single-purchase customers: {timespan_stats['single_purchase_customers']}\")\n",
    "print(f\"Longest customer timespan: {timespan_stats['max_timespan_days']} days\")\n",
    "print(f\"Shortest customer timespan: {timespan_stats['min_timespan_days']} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate median timespan between first and last purchase in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_median_customer_timespan(df):\n",
    "    \"\"\"\n",
    "    Calculate the median time span between first and last purchase for each customer.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing columns 'customer_id' and 'transaction_date'\n",
    "                         as created by process_shopping_history()\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary containing:\n",
    "          - 'median_days': Median number of days between first and last purchase\n",
    "          - 'median_months': Median number of months between first and last purchase\n",
    "          - 'total_active_customers': Number of customers with more than one purchase\n",
    "          - 'single_purchase_customers': Number of customers with only one purchase\n",
    "          - 'max_timespan_days': Longest customer timespan in days\n",
    "          - 'min_timespan_days': Shortest customer timespan in days (excluding single-purchase customers)\n",
    "          - 'q1_days': First quartile of customer timespan in days\n",
    "          - 'q3_days': Third quartile of customer timespan in days\n",
    "    \"\"\"\n",
    "    # Group by customer and get their first and last purchase dates\n",
    "    customer_spans = df.groupby('customer_id').agg({\n",
    "        'transaction_date': ['min', 'max', 'count']\n",
    "    })\n",
    "    \n",
    "    # Flatten column names\n",
    "    customer_spans.columns = ['first_purchase', 'last_purchase', 'purchase_count']\n",
    "    \n",
    "    # Calculate time difference for each customer\n",
    "    customer_spans['timespan_days'] = (\n",
    "        customer_spans['last_purchase'] - customer_spans['first_purchase']\n",
    "    ).dt.total_seconds() / (24 * 60 * 60)  # Convert to days\n",
    "    \n",
    "    # Count customers with single purchase\n",
    "    single_purchase_customers = (customer_spans['purchase_count'] == 1).sum()\n",
    "    \n",
    "    # Filter for customers with more than one purchase for median calculation\n",
    "    multiple_purchase_spans = customer_spans[customer_spans['purchase_count'] > 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    if len(multiple_purchase_spans) > 0:\n",
    "        median_days = multiple_purchase_spans['timespan_days'].median()\n",
    "        median_months = median_days / 30.44  # Using average month length\n",
    "        max_timespan = multiple_purchase_spans['timespan_days'].max()\n",
    "        min_timespan = multiple_purchase_spans['timespan_days'].min()\n",
    "        q1_days = multiple_purchase_spans['timespan_days'].quantile(0.25)\n",
    "        q3_days = multiple_purchase_spans['timespan_days'].quantile(0.75)\n",
    "    else:\n",
    "        median_days = 0\n",
    "        median_months = 0\n",
    "        max_timespan = 0\n",
    "        min_timespan = 0\n",
    "        q1_days = 0\n",
    "        q3_days = 0\n",
    "    \n",
    "    return {\n",
    "        'median_days': round(median_days, 2),\n",
    "        'median_months': round(median_months, 2),\n",
    "        'total_active_customers': len(multiple_purchase_spans),\n",
    "        'single_purchase_customers': single_purchase_customers,\n",
    "        'max_timespan_days': round(max_timespan, 2),\n",
    "        'min_timespan_days': round(min_timespan, 2),\n",
    "        'q1_days': round(q1_days, 2),\n",
    "        'q3_days': round(q3_days, 2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median customer timespan: 3489.0 days (114.62 months)\n",
      "Active customers (>1 purchase): 17132\n",
      "Single-purchase customers: 0\n",
      "First quartile (25%): 3019.0 days\n",
      "Third quartile (75%): 3522.0 days\n",
      "Range: 9.0 to 3529.0 days\n"
     ]
    }
   ],
   "source": [
    "# Calculate median customer timespan\n",
    "timespan_stats = calculate_median_customer_timespan(df)\n",
    "\n",
    "print(f\"Median customer timespan: {timespan_stats['median_days']} days ({timespan_stats['median_months']} months)\")\n",
    "print(f\"Active customers (>1 purchase): {timespan_stats['total_active_customers']}\")\n",
    "print(f\"Single-purchase customers: {timespan_stats['single_purchase_customers']}\")\n",
    "print(f\"First quartile (25%): {timespan_stats['q1_days']} days\")\n",
    "print(f\"Third quartile (75%): {timespan_stats['q3_days']} days\")\n",
    "print(f\"Range: {timespan_stats['min_timespan_days']} to {timespan_stats['max_timespan_days']} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### avg / median number of baskets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_basket_size_metrics(df):\n",
    "    \"\"\"\n",
    "    Calculate average and median basket sizes (number of items) per customer.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing columns 'customer_id' and 'basket_content'\n",
    "                         as created by process_shopping_history()\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary containing:\n",
    "          - 'overall_avg_basket_size': Average basket size across all transactions\n",
    "          - 'overall_median_basket_size': Median basket size across all transactions\n",
    "          - 'avg_basket_size_per_customer': Mean of customer average basket sizes\n",
    "          - 'median_basket_size_per_customer': Median of customer average basket sizes\n",
    "          - 'largest_basket': Size of the largest basket\n",
    "          - 'smallest_basket': Size of the smallest basket\n",
    "          - 'q1_basket_size': First quartile of basket sizes\n",
    "          - 'q3_basket_size': Third quartile of basket sizes\n",
    "    \"\"\"\n",
    "    # Calculate basket sizes for each transaction\n",
    "    df['basket_size'] = df['basket_content'].apply(len)\n",
    "    \n",
    "    # Calculate overall metrics (across all transactions)\n",
    "    overall_avg_size = df['basket_size'].mean()\n",
    "    overall_median_size = df['basket_size'].median()\n",
    "    \n",
    "    # Calculate average basket size for each customer\n",
    "    customer_avg_sizes = df.groupby('customer_id')['basket_size'].mean()\n",
    "    \n",
    "    # Calculate the mean and median of customer averages\n",
    "    avg_size_per_customer = customer_avg_sizes.mean()\n",
    "    median_size_per_customer = customer_avg_sizes.median()\n",
    "    \n",
    "    # Calculate additional statistics\n",
    "    largest_basket = df['basket_size'].max()\n",
    "    smallest_basket = df['basket_size'].min()\n",
    "    q1_size = df['basket_size'].quantile(0.25)\n",
    "    q3_size = df['basket_size'].quantile(0.75)\n",
    "    \n",
    "    return {\n",
    "        'overall_avg_basket_size': round(overall_avg_size, 2),\n",
    "        'overall_median_basket_size': round(overall_median_size, 2),\n",
    "        'avg_basket_size_per_customer': round(avg_size_per_customer, 2),\n",
    "        'median_basket_size_per_customer': round(median_size_per_customer, 2),\n",
    "        'largest_basket': largest_basket,\n",
    "        'smallest_basket': smallest_basket,\n",
    "        'q1_basket_size': round(q1_size, 2),\n",
    "        'q3_basket_size': round(q3_size, 2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Metrics (across all transactions):\n",
      "Average basket size: 10.22 items\n",
      "Median basket size: 8.0 items\n",
      "\n",
      "Per-Customer Metrics:\n",
      "Average of customer average basket sizes: 10.83 items\n",
      "Median of customer average basket sizes: 9.52 items\n",
      "\n",
      "Distribution:\n",
      "First quartile (25%): 4.0 items\n",
      "Third quartile (75%): 13.0 items\n",
      "Range: 0 to 136 items\n"
     ]
    }
   ],
   "source": [
    "# Calculate basket size metrics\n",
    "basket_metrics = calculate_basket_size_metrics(df)\n",
    "\n",
    "print(\"Overall Metrics (across all transactions):\")\n",
    "print(f\"Average basket size: {basket_metrics['overall_avg_basket_size']} items\")\n",
    "print(f\"Median basket size: {basket_metrics['overall_median_basket_size']} items\")\n",
    "\n",
    "print(\"\\nPer-Customer Metrics:\")\n",
    "print(f\"Average of customer average basket sizes: {basket_metrics['avg_basket_size_per_customer']} items\")\n",
    "print(f\"Median of customer average basket sizes: {basket_metrics['median_basket_size_per_customer']} items\")\n",
    "\n",
    "print(\"\\nDistribution:\")\n",
    "print(f\"First quartile (25%): {basket_metrics['q1_basket_size']} items\")\n",
    "print(f\"Third quartile (75%): {basket_metrics['q3_basket_size']} items\")\n",
    "print(f\"Range: {basket_metrics['smallest_basket']} to {basket_metrics['largest_basket']} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flagging Forgotten-Item baskets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import time\n",
    "\n",
    "def flag_forgotten_items_baskets(df, large_basket, max_days, min_forgotten_items, verbose=True):\n",
    "    \"\"\"\n",
    "    Flag forgotten-item baskets based on specified parameters.\n",
    "    Only flags the first qualifying transaction after each large basket.\n",
    "    Handles same-day transactions based on their order in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame with columns customer_id, transaction_date, basket_content\n",
    "    large_basket (int): Minimum number of items for a basket to be considered large\n",
    "    max_days (int): Maximum days window after large basket\n",
    "    min_forgotten_items (int): Minimum items in subsequent basket to be flagged\n",
    "    verbose (bool): Whether to print progress updates\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Original DataFrame with additional forgotten_item_flag column\n",
    "    \"\"\"\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Initialize the forgotten_item_flag column with 0\n",
    "    df['forgotten_item_flag'] = 0\n",
    "    \n",
    "    # Get unique customers\n",
    "    unique_customers = df['customer_id'].unique()\n",
    "    total_customers = len(unique_customers)\n",
    "    \n",
    "    # Initialize counters for progress tracking\n",
    "    processed_customers = 0\n",
    "    last_print_time = time.time()\n",
    "    \n",
    "    print(f\"\\nStarting analysis with parameters:\")\n",
    "    print(f\"Large basket threshold: {large_basket} items\")\n",
    "    print(f\"Maximum days window: {max_days} days\")\n",
    "    print(f\"Minimum forgotten items: {min_forgotten_items} items\")\n",
    "    print(f\"\\nProcessing {total_customers} customers...\")\n",
    "    \n",
    "    # Process each customer's transactions\n",
    "    for customer_id in unique_customers:\n",
    "        # Get customer's transactions\n",
    "        customer_df = df[df['customer_id'] == customer_id].copy()\n",
    "        \n",
    "        # Sort by transaction date\n",
    "        customer_df = customer_df.sort_values('transaction_date')\n",
    "        \n",
    "        # Get indices of large baskets\n",
    "        large_basket_mask = customer_df['basket_content'].apply(len) >= large_basket\n",
    "        large_basket_indices = customer_df[large_basket_mask].index\n",
    "        \n",
    "        # For each large basket\n",
    "        for large_basket_idx in large_basket_indices:\n",
    "            large_basket_date = customer_df.loc[large_basket_idx, 'transaction_date']\n",
    "            window_end = large_basket_date + timedelta(days=max_days)\n",
    "            \n",
    "            # Find subsequent purchases within the time window\n",
    "            # Using index comparison to respect transaction order\n",
    "            subsequent_purchases = customer_df[\n",
    "                (customer_df.index > large_basket_idx) &  # After current basket in order\n",
    "                (customer_df['transaction_date'] <= window_end)  # Within time window\n",
    "            ]\n",
    "            \n",
    "            # Check each subsequent purchase until we find the first qualifying one\n",
    "            for idx, row in subsequent_purchases.iterrows():\n",
    "                if len(row['basket_content']) >= min_forgotten_items:\n",
    "                    df.loc[idx, 'forgotten_item_flag'] = 1\n",
    "                    break  # Exit the loop after finding the first qualifying transaction\n",
    "        \n",
    "        processed_customers += 1\n",
    "        \n",
    "        # Print progress every 1000 customers or if 5 seconds have passed\n",
    "        current_time = time.time()\n",
    "        if verbose and (processed_customers % 1000 == 0 or current_time - last_print_time >= 5):\n",
    "            # Calculate current number of flagged transactions directly from the DataFrame\n",
    "            current_flagged = df['forgotten_item_flag'].sum()\n",
    "            print(f\"Processed {processed_customers}/{total_customers} customers. \"\n",
    "                  f\"Found {current_flagged} forgotten-item baskets so far. \"\n",
    "                  f\"({round(processed_customers/total_customers*100, 2)}% complete)\")\n",
    "            last_print_time = current_time\n",
    "    \n",
    "    # Get final count of flagged transactions\n",
    "    total_flagged = df['forgotten_item_flag'].sum()\n",
    "    \n",
    "    # Print final statistics\n",
    "    print(\"\\nAnalysis complete!\")\n",
    "    print(f\"Total purchases analyzed: {len(df)}\")\n",
    "    print(f\"Number of forgotten-item baskets identified: {total_flagged}\")\n",
    "    print(f\"Percentage of forgotten-item baskets: \"\n",
    "          f\"{round(total_flagged/len(df)*100, 2)}%\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting analysis with parameters:\n",
      "Large basket threshold: 10 items\n",
      "Maximum days window: 2 days\n",
      "Minimum forgotten items: 10 items\n",
      "\n",
      "Processing 17132 customers...\n",
      "Processed 46/17132 customers. Found 4166 forgotten-item baskets so far. (0.27% complete)\n",
      "Processed 92/17132 customers. Found 6927 forgotten-item baskets so far. (0.54% complete)\n",
      "Processed 162/17132 customers. Found 8659 forgotten-item baskets so far. (0.95% complete)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m MIN_FORGOTTEN_ITEMS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# following basket should have 5 or more items\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Apply the flagging\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m df_flagged_2 \u001b[38;5;241m=\u001b[39m flag_forgotten_items_baskets(df, \n\u001b[0;32m     11\u001b[0m                                 large_basket\u001b[38;5;241m=\u001b[39mLARGE_BASKET,\n\u001b[0;32m     12\u001b[0m                                 max_days\u001b[38;5;241m=\u001b[39mMAX_DAYS,\n\u001b[0;32m     13\u001b[0m                                 min_forgotten_items\u001b[38;5;241m=\u001b[39mMIN_FORGOTTEN_ITEMS)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# View results\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTotal purchases:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df_flagged_2))\n",
      "Cell \u001b[1;32mIn[13], line 62\u001b[0m, in \u001b[0;36mflag_forgotten_items_baskets\u001b[1;34m(df, large_basket, max_days, min_forgotten_items, verbose)\u001b[0m\n\u001b[0;32m     56\u001b[0m window_end \u001b[38;5;241m=\u001b[39m large_basket_date \u001b[38;5;241m+\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39mmax_days)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Find subsequent purchases within the time window\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Using index comparison to respect transaction order\u001b[39;00m\n\u001b[0;32m     60\u001b[0m subsequent_purchases \u001b[38;5;241m=\u001b[39m customer_df[\n\u001b[0;32m     61\u001b[0m     (customer_df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m>\u001b[39m large_basket_idx) \u001b[38;5;241m&\u001b[39m  \u001b[38;5;66;03m# After current basket in order\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m     (customer_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransaction_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m window_end)  \u001b[38;5;66;03m# Within time window\u001b[39;00m\n\u001b[0;32m     63\u001b[0m ]\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Check each subsequent purchase until we find the first qualifying one\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m subsequent_purchases\u001b[38;5;241m.\u001b[39miterrows():\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:52\u001b[0m, in \u001b[0;36mOpsMixin.__le__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__le__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__le__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmp_method(other, operator\u001b[38;5;241m.\u001b[39mle)\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcomparison_op(lvalues, rvalues, op)\n\u001b[0;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:330\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    322\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLengths must match to compare\u001b[39m\u001b[38;5;124m\"\u001b[39m, lvalues\u001b[38;5;241m.\u001b[39mshape, rvalues\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    323\u001b[0m         )\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    326\u001b[0m     (\u001b[38;5;28misinstance\u001b[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m NaT)\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[0;32m    328\u001b[0m ):\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;66;03m# Call the method on lvalues\u001b[39;00m\n\u001b[1;32m--> 330\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m op(lvalues, rvalues)\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_scalar(rvalues) \u001b[38;5;129;01mand\u001b[39;00m isna(rvalues):  \u001b[38;5;66;03m# TODO: but not pd.NA?\u001b[39;00m\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;66;03m# numpy does not like comparisons vs None\u001b[39;00m\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;129;01mis\u001b[39;00m operator\u001b[38;5;241m.\u001b[39mne:\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:52\u001b[0m, in \u001b[0;36mOpsMixin.__le__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__le__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__le__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmp_method(other, operator\u001b[38;5;241m.\u001b[39mle)\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:1026\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1024\u001b[0m o_mask \u001b[38;5;241m=\u001b[39m isna(other)\n\u001b[0;32m   1025\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_isnan \u001b[38;5;241m|\u001b[39m o_mask\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   1027\u001b[0m     nat_result \u001b[38;5;241m=\u001b[39m op \u001b[38;5;129;01mis\u001b[39;00m operator\u001b[38;5;241m.\u001b[39mne\n\u001b[0;32m   1028\u001b[0m     np\u001b[38;5;241m.\u001b[39mputmask(result, mask, nat_result)\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:55\u001b[0m, in \u001b[0;36m_any\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prod\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     52\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_prod(a, axis, dtype, out, keepdims, initial, where)\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_any\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "\n",
    "# Assuming df is your original DataFrame from load_shopping_data()\n",
    "# Set parameters\n",
    "LARGE_BASKET = 10  # baskets with 20 or more items are considered large\n",
    "MAX_DAYS = 2      # look at purchases up to 2 days after\n",
    "MIN_FORGOTTEN_ITEMS = 10  # following basket should have 5 or more items\n",
    "\n",
    "# Apply the flagging\n",
    "df_flagged_2 = flag_forgotten_items_baskets(df, \n",
    "                                large_basket=LARGE_BASKET,\n",
    "                                max_days=MAX_DAYS,\n",
    "                                min_forgotten_items=MIN_FORGOTTEN_ITEMS)\n",
    "\n",
    "# View results\n",
    "print(\"\\nTotal purchases:\", len(df_flagged_2))\n",
    "print(\"Number of forgotten-item baskets:\", df_flagged_2['forgotten_item_flag'].sum())\n",
    "print(\"Percentage of forgotten-item baskets:\", \n",
    "      round(df_flagged_2['forgotten_item_flag'].mean() * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving results to flagged_baskets_results_2_tafeng.csv...\n",
      "Results saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Optional: Save results to CSV\n",
    "output_path = \"flagged_baskets_results_2_tafeng.csv\"\n",
    "print(f\"\\nSaving results to {output_path}...\")\n",
    "df_flagged_2.to_csv(output_path, index=False)\n",
    "print(\"Results saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting analysis with parameters:\n",
      "Large basket threshold: 10 items\n",
      "Maximum days window: 1 days\n",
      "Minimum forgotten items: 10 items\n",
      "\n",
      "Processing 32266 customers...\n",
      "Processed 1000/32266 customers. Found 31 forgotten-item baskets so far. (3.1% complete)\n",
      "Processed 2000/32266 customers. Found 43 forgotten-item baskets so far. (6.2% complete)\n",
      "Processed 3000/32266 customers. Found 53 forgotten-item baskets so far. (9.3% complete)\n",
      "Processed 4000/32266 customers. Found 70 forgotten-item baskets so far. (12.4% complete)\n",
      "Processed 5000/32266 customers. Found 85 forgotten-item baskets so far. (15.5% complete)\n",
      "Processed 6000/32266 customers. Found 94 forgotten-item baskets so far. (18.6% complete)\n",
      "Processed 7000/32266 customers. Found 98 forgotten-item baskets so far. (21.69% complete)\n",
      "Processed 8000/32266 customers. Found 106 forgotten-item baskets so far. (24.79% complete)\n",
      "Processed 9000/32266 customers. Found 118 forgotten-item baskets so far. (27.89% complete)\n",
      "Processed 10000/32266 customers. Found 128 forgotten-item baskets so far. (30.99% complete)\n",
      "Processed 11000/32266 customers. Found 148 forgotten-item baskets so far. (34.09% complete)\n",
      "Processed 12000/32266 customers. Found 157 forgotten-item baskets so far. (37.19% complete)\n",
      "Processed 13000/32266 customers. Found 166 forgotten-item baskets so far. (40.29% complete)\n",
      "Processed 14000/32266 customers. Found 177 forgotten-item baskets so far. (43.39% complete)\n",
      "Processed 15000/32266 customers. Found 185 forgotten-item baskets so far. (46.49% complete)\n",
      "Processed 16000/32266 customers. Found 194 forgotten-item baskets so far. (49.59% complete)\n",
      "Processed 17000/32266 customers. Found 204 forgotten-item baskets so far. (52.69% complete)\n",
      "Processed 18000/32266 customers. Found 212 forgotten-item baskets so far. (55.79% complete)\n",
      "Processed 19000/32266 customers. Found 218 forgotten-item baskets so far. (58.89% complete)\n",
      "Processed 20000/32266 customers. Found 222 forgotten-item baskets so far. (61.98% complete)\n",
      "Processed 21000/32266 customers. Found 229 forgotten-item baskets so far. (65.08% complete)\n",
      "Processed 22000/32266 customers. Found 251 forgotten-item baskets so far. (68.18% complete)\n",
      "Processed 23000/32266 customers. Found 255 forgotten-item baskets so far. (71.28% complete)\n",
      "Processed 24000/32266 customers. Found 258 forgotten-item baskets so far. (74.38% complete)\n",
      "Processed 25000/32266 customers. Found 260 forgotten-item baskets so far. (77.48% complete)\n",
      "Processed 26000/32266 customers. Found 262 forgotten-item baskets so far. (80.58% complete)\n",
      "Processed 27000/32266 customers. Found 269 forgotten-item baskets so far. (83.68% complete)\n",
      "Processed 28000/32266 customers. Found 282 forgotten-item baskets so far. (86.78% complete)\n",
      "Processed 29000/32266 customers. Found 304 forgotten-item baskets so far. (89.88% complete)\n",
      "Processed 30000/32266 customers. Found 313 forgotten-item baskets so far. (92.98% complete)\n",
      "Processed 31000/32266 customers. Found 318 forgotten-item baskets so far. (96.08% complete)\n",
      "Processed 32000/32266 customers. Found 318 forgotten-item baskets so far. (99.18% complete)\n",
      "\n",
      "Analysis complete!\n",
      "Total purchases analyzed: 119578\n",
      "Number of forgotten-item baskets identified: 324\n",
      "Percentage of forgotten-item baskets: 0.27%\n",
      "\n",
      "Total purchases: 119578\n",
      "Number of forgotten-item baskets: 324\n",
      "Percentage of forgotten-item baskets: 0.27 %\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "\n",
    "# Assuming df is your original DataFrame from load_shopping_data()\n",
    "# Set parameters\n",
    "LARGE_BASKET = 10  # baskets with 20 or more items are considered large\n",
    "MAX_DAYS = 1      # look at purchases up to 2 days after\n",
    "MIN_FORGOTTEN_ITEMS = 10  # following basket should have 5 or more items\n",
    "\n",
    "# Apply the flagging\n",
    "df_flagged_1 = flag_forgotten_items_baskets(df, \n",
    "                                large_basket=LARGE_BASKET,\n",
    "                                max_days=MAX_DAYS,\n",
    "                                min_forgotten_items=MIN_FORGOTTEN_ITEMS)\n",
    "\n",
    "# View results\n",
    "print(\"\\nTotal purchases:\", len(df_flagged_1))\n",
    "print(\"Number of forgotten-item baskets:\", df_flagged_1['forgotten_item_flag'].sum())\n",
    "print(\"Percentage of forgotten-item baskets:\", \n",
    "      round(df_flagged_1['forgotten_item_flag'].mean() * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving results to flagged_baskets_results_1_tafeng.csv...\n",
      "Results saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# # Optional: Save results to CSV\n",
    "output_path = \"flagged_baskets_results_1_tafeng.csv\"\n",
    "print(f\"\\nSaving results to {output_path}...\")\n",
    "df_flagged_1.to_csv(output_path, index=False)\n",
    "print(\"Results saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting analysis with parameters:\n",
      "Large basket threshold: 10 items\n",
      "Maximum days window: 0 days\n",
      "Minimum forgotten items: 10 items\n",
      "\n",
      "Processing 32266 customers...\n",
      "Processed 1000/32266 customers. Found 0 forgotten-item baskets so far. (3.1% complete)\n",
      "Processed 2000/32266 customers. Found 0 forgotten-item baskets so far. (6.2% complete)\n",
      "Processed 3000/32266 customers. Found 0 forgotten-item baskets so far. (9.3% complete)\n",
      "Processed 4000/32266 customers. Found 0 forgotten-item baskets so far. (12.4% complete)\n",
      "Processed 5000/32266 customers. Found 0 forgotten-item baskets so far. (15.5% complete)\n",
      "Processed 6000/32266 customers. Found 0 forgotten-item baskets so far. (18.6% complete)\n",
      "Processed 7000/32266 customers. Found 0 forgotten-item baskets so far. (21.69% complete)\n",
      "Processed 8000/32266 customers. Found 0 forgotten-item baskets so far. (24.79% complete)\n",
      "Processed 9000/32266 customers. Found 0 forgotten-item baskets so far. (27.89% complete)\n",
      "Processed 10000/32266 customers. Found 0 forgotten-item baskets so far. (30.99% complete)\n",
      "Processed 11000/32266 customers. Found 0 forgotten-item baskets so far. (34.09% complete)\n",
      "Processed 12000/32266 customers. Found 0 forgotten-item baskets so far. (37.19% complete)\n",
      "Processed 13000/32266 customers. Found 0 forgotten-item baskets so far. (40.29% complete)\n",
      "Processed 14000/32266 customers. Found 0 forgotten-item baskets so far. (43.39% complete)\n",
      "Processed 15000/32266 customers. Found 0 forgotten-item baskets so far. (46.49% complete)\n",
      "Processed 16000/32266 customers. Found 0 forgotten-item baskets so far. (49.59% complete)\n",
      "Processed 17000/32266 customers. Found 0 forgotten-item baskets so far. (52.69% complete)\n",
      "Processed 18000/32266 customers. Found 0 forgotten-item baskets so far. (55.79% complete)\n",
      "Processed 19000/32266 customers. Found 0 forgotten-item baskets so far. (58.89% complete)\n",
      "Processed 20000/32266 customers. Found 0 forgotten-item baskets so far. (61.98% complete)\n",
      "Processed 21000/32266 customers. Found 0 forgotten-item baskets so far. (65.08% complete)\n",
      "Processed 22000/32266 customers. Found 0 forgotten-item baskets so far. (68.18% complete)\n",
      "Processed 23000/32266 customers. Found 0 forgotten-item baskets so far. (71.28% complete)\n",
      "Processed 24000/32266 customers. Found 0 forgotten-item baskets so far. (74.38% complete)\n",
      "Processed 25000/32266 customers. Found 0 forgotten-item baskets so far. (77.48% complete)\n",
      "Processed 26000/32266 customers. Found 0 forgotten-item baskets so far. (80.58% complete)\n",
      "Processed 27000/32266 customers. Found 0 forgotten-item baskets so far. (83.68% complete)\n",
      "Processed 28000/32266 customers. Found 0 forgotten-item baskets so far. (86.78% complete)\n",
      "Processed 29000/32266 customers. Found 0 forgotten-item baskets so far. (89.88% complete)\n",
      "Processed 30000/32266 customers. Found 0 forgotten-item baskets so far. (92.98% complete)\n",
      "Processed 31000/32266 customers. Found 0 forgotten-item baskets so far. (96.08% complete)\n",
      "Processed 32000/32266 customers. Found 0 forgotten-item baskets so far. (99.18% complete)\n",
      "\n",
      "Analysis complete!\n",
      "Total purchases analyzed: 119578\n",
      "Number of forgotten-item baskets identified: 0\n",
      "Percentage of forgotten-item baskets: 0.0%\n",
      "\n",
      "Total purchases: 119578\n",
      "Number of forgotten-item baskets: 0\n",
      "Percentage of forgotten-item baskets: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "\n",
    "# Assuming df is your original DataFrame from load_shopping_data()\n",
    "# Set parameters\n",
    "LARGE_BASKET = 10  # baskets with 20 or more items are considered large\n",
    "MAX_DAYS = 0      # look at purchases up to 2 days after\n",
    "MIN_FORGOTTEN_ITEMS = 10  # following basket should have 5 or more items\n",
    "\n",
    "# Apply the flagging\n",
    "df_flagged_0 = flag_forgotten_items_baskets(df, \n",
    "                                large_basket=LARGE_BASKET,\n",
    "                                max_days=MAX_DAYS,\n",
    "                                min_forgotten_items=MIN_FORGOTTEN_ITEMS)\n",
    "\n",
    "# View results\n",
    "print(\"\\nTotal purchases:\", len(df_flagged_0))\n",
    "print(\"Number of forgotten-item baskets:\", df_flagged_0['forgotten_item_flag'].sum())\n",
    "print(\"Percentage of forgotten-item baskets:\", \n",
    "      round(df_flagged_0['forgotten_item_flag'].mean() * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving results to flagged_baskets_results_0_tafeng.csv...\n",
      "Results saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# # Optional: Save results to CSV\n",
    "output_path = \"flagged_baskets_results_0_tafeng.csv\"\n",
    "print(f\"\\nSaving results to {output_path}...\")\n",
    "df_flagged_0.to_csv(output_path, index=False)\n",
    "print(\"Results saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting analysis with parameters:\n",
      "Large basket threshold: 10 items\n",
      "Maximum days window: 2 days\n",
      "Minimum forgotten items: 1 items\n",
      "\n",
      "Processing 32266 customers...\n",
      "Processed 1000/32266 customers. Found 168 forgotten-item baskets so far. (3.1% complete)\n",
      "Processed 2000/32266 customers. Found 278 forgotten-item baskets so far. (6.2% complete)\n",
      "Processed 3000/32266 customers. Found 364 forgotten-item baskets so far. (9.3% complete)\n",
      "Processed 4000/32266 customers. Found 469 forgotten-item baskets so far. (12.4% complete)\n",
      "Processed 5000/32266 customers. Found 566 forgotten-item baskets so far. (15.5% complete)\n",
      "Processed 6000/32266 customers. Found 679 forgotten-item baskets so far. (18.6% complete)\n",
      "Processed 7000/32266 customers. Found 780 forgotten-item baskets so far. (21.69% complete)\n",
      "Processed 8000/32266 customers. Found 852 forgotten-item baskets so far. (24.79% complete)\n",
      "Processed 9000/32266 customers. Found 936 forgotten-item baskets so far. (27.89% complete)\n",
      "Processed 10000/32266 customers. Found 1018 forgotten-item baskets so far. (30.99% complete)\n",
      "Processed 11000/32266 customers. Found 1112 forgotten-item baskets so far. (34.09% complete)\n",
      "Processed 12000/32266 customers. Found 1200 forgotten-item baskets so far. (37.19% complete)\n",
      "Processed 13000/32266 customers. Found 1259 forgotten-item baskets so far. (40.29% complete)\n",
      "Processed 14000/32266 customers. Found 1344 forgotten-item baskets so far. (43.39% complete)\n",
      "Processed 15000/32266 customers. Found 1398 forgotten-item baskets so far. (46.49% complete)\n",
      "Processed 16000/32266 customers. Found 1522 forgotten-item baskets so far. (49.59% complete)\n",
      "Processed 17000/32266 customers. Found 1587 forgotten-item baskets so far. (52.69% complete)\n",
      "Processed 18000/32266 customers. Found 1674 forgotten-item baskets so far. (55.79% complete)\n",
      "Processed 19000/32266 customers. Found 1735 forgotten-item baskets so far. (58.89% complete)\n",
      "Processed 20000/32266 customers. Found 1785 forgotten-item baskets so far. (61.98% complete)\n",
      "Processed 21000/32266 customers. Found 1835 forgotten-item baskets so far. (65.08% complete)\n",
      "Processed 22000/32266 customers. Found 2044 forgotten-item baskets so far. (68.18% complete)\n",
      "Processed 23000/32266 customers. Found 2083 forgotten-item baskets so far. (71.28% complete)\n",
      "Processed 24000/32266 customers. Found 2110 forgotten-item baskets so far. (74.38% complete)\n",
      "Processed 25000/32266 customers. Found 2176 forgotten-item baskets so far. (77.48% complete)\n",
      "Processed 26000/32266 customers. Found 2219 forgotten-item baskets so far. (80.58% complete)\n",
      "Processed 27000/32266 customers. Found 2285 forgotten-item baskets so far. (83.68% complete)\n",
      "Processed 28000/32266 customers. Found 2342 forgotten-item baskets so far. (86.78% complete)\n",
      "Processed 29000/32266 customers. Found 2444 forgotten-item baskets so far. (89.88% complete)\n",
      "Processed 30000/32266 customers. Found 2507 forgotten-item baskets so far. (92.98% complete)\n",
      "Processed 31000/32266 customers. Found 2558 forgotten-item baskets so far. (96.08% complete)\n",
      "Processed 32000/32266 customers. Found 2574 forgotten-item baskets so far. (99.18% complete)\n",
      "\n",
      "Analysis complete!\n",
      "Total purchases analyzed: 119578\n",
      "Number of forgotten-item baskets identified: 2586\n",
      "Percentage of forgotten-item baskets: 2.16%\n",
      "\n",
      "Total purchases: 119578\n",
      "Number of forgotten-item baskets: 2586\n",
      "Percentage of forgotten-item baskets: 2.16 %\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "\n",
    "# Assuming df is your original DataFrame from load_shopping_data()\n",
    "# Set parameters\n",
    "LARGE_BASKET = 10  # baskets with 20 or more items are considered large\n",
    "MAX_DAYS = 2      # look at purchases up to 2 days after\n",
    "MIN_FORGOTTEN_ITEMS = 1  # following basket should have 5 or more items\n",
    "\n",
    "# Apply the flagging\n",
    "df_flagged_2_1 = flag_forgotten_items_baskets(df, \n",
    "                                large_basket=LARGE_BASKET,\n",
    "                                max_days=MAX_DAYS,\n",
    "                                min_forgotten_items=MIN_FORGOTTEN_ITEMS)\n",
    "\n",
    "# View results\n",
    "print(\"\\nTotal purchases:\", len(df_flagged_2_1))\n",
    "print(\"Number of forgotten-item baskets:\", df_flagged_2_1['forgotten_item_flag'].sum())\n",
    "print(\"Percentage of forgotten-item baskets:\", \n",
    "      round(df_flagged_2_1['forgotten_item_flag'].mean() * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving results to flagged_baskets_results_2_min_forg_1_tafeng.csv...\n",
      "Results saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# # Optional: Save results to CSV\n",
    "output_path = \"flagged_baskets_results_2_min_forg_1_tafeng.csv\"\n",
    "print(f\"\\nSaving results to {output_path}...\")\n",
    "df_flagged_2_1.to_csv(output_path, index=False)\n",
    "print(\"Results saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting analysis with parameters:\n",
      "Large basket threshold: 10 items\n",
      "Maximum days window: 1 days\n",
      "Minimum forgotten items: 1 items\n",
      "\n",
      "Processing 32266 customers...\n",
      "Processed 1000/32266 customers. Found 104 forgotten-item baskets so far. (3.1% complete)\n",
      "Processed 2000/32266 customers. Found 170 forgotten-item baskets so far. (6.2% complete)\n",
      "Processed 3000/32266 customers. Found 231 forgotten-item baskets so far. (9.3% complete)\n",
      "Processed 4000/32266 customers. Found 300 forgotten-item baskets so far. (12.4% complete)\n",
      "Processed 5000/32266 customers. Found 356 forgotten-item baskets so far. (15.5% complete)\n",
      "Processed 6000/32266 customers. Found 423 forgotten-item baskets so far. (18.6% complete)\n",
      "Processed 7000/32266 customers. Found 472 forgotten-item baskets so far. (21.69% complete)\n",
      "Processed 8000/32266 customers. Found 514 forgotten-item baskets so far. (24.79% complete)\n",
      "Processed 9000/32266 customers. Found 559 forgotten-item baskets so far. (27.89% complete)\n",
      "Processed 10000/32266 customers. Found 600 forgotten-item baskets so far. (30.99% complete)\n",
      "Processed 11000/32266 customers. Found 647 forgotten-item baskets so far. (34.09% complete)\n",
      "Processed 12000/32266 customers. Found 699 forgotten-item baskets so far. (37.19% complete)\n",
      "Processed 13000/32266 customers. Found 735 forgotten-item baskets so far. (40.29% complete)\n",
      "Processed 14000/32266 customers. Found 790 forgotten-item baskets so far. (43.39% complete)\n",
      "Processed 15000/32266 customers. Found 827 forgotten-item baskets so far. (46.49% complete)\n",
      "Processed 16000/32266 customers. Found 903 forgotten-item baskets so far. (49.59% complete)\n",
      "Processed 17000/32266 customers. Found 946 forgotten-item baskets so far. (52.69% complete)\n",
      "Processed 18000/32266 customers. Found 996 forgotten-item baskets so far. (55.79% complete)\n",
      "Processed 19000/32266 customers. Found 1031 forgotten-item baskets so far. (58.89% complete)\n",
      "Processed 20000/32266 customers. Found 1058 forgotten-item baskets so far. (61.98% complete)\n",
      "Processed 21000/32266 customers. Found 1090 forgotten-item baskets so far. (65.08% complete)\n",
      "Processed 22000/32266 customers. Found 1216 forgotten-item baskets so far. (68.18% complete)\n",
      "Processed 23000/32266 customers. Found 1244 forgotten-item baskets so far. (71.28% complete)\n",
      "Processed 24000/32266 customers. Found 1265 forgotten-item baskets so far. (74.38% complete)\n",
      "Processed 25000/32266 customers. Found 1302 forgotten-item baskets so far. (77.48% complete)\n",
      "Processed 26000/32266 customers. Found 1325 forgotten-item baskets so far. (80.58% complete)\n",
      "Processed 27000/32266 customers. Found 1367 forgotten-item baskets so far. (83.68% complete)\n",
      "Processed 28000/32266 customers. Found 1407 forgotten-item baskets so far. (86.78% complete)\n",
      "Processed 29000/32266 customers. Found 1468 forgotten-item baskets so far. (89.88% complete)\n",
      "Processed 30000/32266 customers. Found 1506 forgotten-item baskets so far. (92.98% complete)\n",
      "Processed 31000/32266 customers. Found 1534 forgotten-item baskets so far. (96.08% complete)\n",
      "Processed 32000/32266 customers. Found 1539 forgotten-item baskets so far. (99.18% complete)\n",
      "\n",
      "Analysis complete!\n",
      "Total purchases analyzed: 119578\n",
      "Number of forgotten-item baskets identified: 1551\n",
      "Percentage of forgotten-item baskets: 1.3%\n",
      "\n",
      "Total purchases: 119578\n",
      "Number of forgotten-item baskets: 1551\n",
      "Percentage of forgotten-item baskets: 1.3 %\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "\n",
    "# Assuming df is your original DataFrame from load_shopping_data()\n",
    "# Set parameters\n",
    "LARGE_BASKET = 10  # baskets with 20 or more items are considered large\n",
    "MAX_DAYS = 1      # look at purchases up to 2 days after\n",
    "MIN_FORGOTTEN_ITEMS = 1  # following basket should have 5 or more items\n",
    "\n",
    "# Apply the flagging\n",
    "df_flagged_1_1 = flag_forgotten_items_baskets(df, \n",
    "                                large_basket=LARGE_BASKET,\n",
    "                                max_days=MAX_DAYS,\n",
    "                                min_forgotten_items=MIN_FORGOTTEN_ITEMS)\n",
    "\n",
    "# View results\n",
    "print(\"\\nTotal purchases:\", len(df_flagged_1_1))\n",
    "print(\"Number of forgotten-item baskets:\", df_flagged_1_1['forgotten_item_flag'].sum())\n",
    "print(\"Percentage of forgotten-item baskets:\", \n",
    "      round(df_flagged_1_1['forgotten_item_flag'].mean() * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving results to flagged_baskets_results_1_min_forg_1_tafeng.csv...\n",
      "Results saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# # Optional: Save results to CSV\n",
    "output_path = \"flagged_baskets_results_1_min_forg_1_tafeng.csv\"\n",
    "print(f\"\\nSaving results to {output_path}...\")\n",
    "df_flagged_1_1.to_csv(output_path, index=False)\n",
    "print(\"Results saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting analysis with parameters:\n",
      "Large basket threshold: 10 items\n",
      "Maximum days window: 0 days\n",
      "Minimum forgotten items: 1 items\n",
      "\n",
      "Processing 32266 customers...\n",
      "Processed 1000/32266 customers. Found 0 forgotten-item baskets so far. (3.1% complete)\n",
      "Processed 2000/32266 customers. Found 0 forgotten-item baskets so far. (6.2% complete)\n",
      "Processed 3000/32266 customers. Found 0 forgotten-item baskets so far. (9.3% complete)\n",
      "Processed 4000/32266 customers. Found 0 forgotten-item baskets so far. (12.4% complete)\n",
      "Processed 5000/32266 customers. Found 0 forgotten-item baskets so far. (15.5% complete)\n",
      "Processed 6000/32266 customers. Found 0 forgotten-item baskets so far. (18.6% complete)\n",
      "Processed 7000/32266 customers. Found 0 forgotten-item baskets so far. (21.69% complete)\n",
      "Processed 8000/32266 customers. Found 0 forgotten-item baskets so far. (24.79% complete)\n",
      "Processed 9000/32266 customers. Found 0 forgotten-item baskets so far. (27.89% complete)\n",
      "Processed 10000/32266 customers. Found 0 forgotten-item baskets so far. (30.99% complete)\n",
      "Processed 11000/32266 customers. Found 0 forgotten-item baskets so far. (34.09% complete)\n",
      "Processed 12000/32266 customers. Found 0 forgotten-item baskets so far. (37.19% complete)\n",
      "Processed 13000/32266 customers. Found 0 forgotten-item baskets so far. (40.29% complete)\n",
      "Processed 14000/32266 customers. Found 0 forgotten-item baskets so far. (43.39% complete)\n",
      "Processed 15000/32266 customers. Found 0 forgotten-item baskets so far. (46.49% complete)\n",
      "Processed 16000/32266 customers. Found 0 forgotten-item baskets so far. (49.59% complete)\n",
      "Processed 17000/32266 customers. Found 0 forgotten-item baskets so far. (52.69% complete)\n",
      "Processed 18000/32266 customers. Found 0 forgotten-item baskets so far. (55.79% complete)\n",
      "Processed 19000/32266 customers. Found 0 forgotten-item baskets so far. (58.89% complete)\n",
      "Processed 20000/32266 customers. Found 0 forgotten-item baskets so far. (61.98% complete)\n",
      "Processed 21000/32266 customers. Found 0 forgotten-item baskets so far. (65.08% complete)\n",
      "Processed 22000/32266 customers. Found 0 forgotten-item baskets so far. (68.18% complete)\n",
      "Processed 23000/32266 customers. Found 0 forgotten-item baskets so far. (71.28% complete)\n",
      "Processed 24000/32266 customers. Found 0 forgotten-item baskets so far. (74.38% complete)\n",
      "Processed 25000/32266 customers. Found 0 forgotten-item baskets so far. (77.48% complete)\n",
      "Processed 26000/32266 customers. Found 0 forgotten-item baskets so far. (80.58% complete)\n",
      "Processed 27000/32266 customers. Found 0 forgotten-item baskets so far. (83.68% complete)\n",
      "Processed 28000/32266 customers. Found 0 forgotten-item baskets so far. (86.78% complete)\n",
      "Processed 29000/32266 customers. Found 0 forgotten-item baskets so far. (89.88% complete)\n",
      "Processed 30000/32266 customers. Found 0 forgotten-item baskets so far. (92.98% complete)\n",
      "Processed 31000/32266 customers. Found 0 forgotten-item baskets so far. (96.08% complete)\n",
      "Processed 32000/32266 customers. Found 0 forgotten-item baskets so far. (99.18% complete)\n",
      "\n",
      "Analysis complete!\n",
      "Total purchases analyzed: 119578\n",
      "Number of forgotten-item baskets identified: 0\n",
      "Percentage of forgotten-item baskets: 0.0%\n",
      "\n",
      "Total purchases: 119578\n",
      "Number of forgotten-item baskets: 0\n",
      "Percentage of forgotten-item baskets: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "\n",
    "# Assuming df is your original DataFrame from load_shopping_data()\n",
    "# Set parameters\n",
    "LARGE_BASKET = 10  # baskets with 20 or more items are considered large\n",
    "MAX_DAYS = 0      # look at purchases up to 2 days after\n",
    "MIN_FORGOTTEN_ITEMS = 1  # following basket should have 5 or more items\n",
    "\n",
    "# Apply the flagging\n",
    "df_flagged_0_1 = flag_forgotten_items_baskets(df, \n",
    "                                large_basket=LARGE_BASKET,\n",
    "                                max_days=MAX_DAYS,\n",
    "                                min_forgotten_items=MIN_FORGOTTEN_ITEMS)\n",
    "\n",
    "# View results\n",
    "print(\"\\nTotal purchases:\", len(df_flagged_0_1))\n",
    "print(\"Number of forgotten-item baskets:\", df_flagged_0_1['forgotten_item_flag'].sum())\n",
    "print(\"Percentage of forgotten-item baskets:\", \n",
    "      round(df_flagged_0_1['forgotten_item_flag'].mean() * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving results to flagged_baskets_results_0_min_forg_1_tafeng.csv...\n",
      "Results saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# # Optional: Save results to CSV\n",
    "output_path = \"flagged_baskets_results_0_min_forg_1_tafeng.csv\"\n",
    "print(f\"\\nSaving results to {output_path}...\")\n",
    "df_flagged_0_1.to_csv(output_path, index=False)\n",
    "print(\"Results saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying the baskets that are considered 'forgotten item' purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single dataset version\n",
    "def identify_forgotten_item_baskets(df, max_days=0, max_items=1, large_basket_threshold=10):\n",
    "    # Sort the dataframe by customer_id and next_basket_id (date)\n",
    "    df = df.sort_values(['customer_id', 'next_basket_id'])\n",
    "    \n",
    "    # Convert next_basket_id to datetime\n",
    "    df['next_basket_date'] = pd.to_datetime(df['next_basket_id'].str.split('_').str[:3].str.join('-'))\n",
    "    \n",
    "    # Initialize the forgotten_item_basket column\n",
    "    df['forgotten_item_basket'] = 0\n",
    "    \n",
    "    # Group by customer_id\n",
    "    for customer_id, group in df.groupby('customer_id'):\n",
    "        large_basket_date = None\n",
    "        \n",
    "        for index, row in group.iterrows():\n",
    "            actual_basket = str(row['actual_basket']).split(',')\n",
    "            \n",
    "            # Check if it's a large basket\n",
    "            if len(actual_basket) >= large_basket_threshold:\n",
    "                large_basket_date = row['next_basket_date']\n",
    "            elif large_basket_date is not None:\n",
    "                # Check if it's a potential forgotten-item basket\n",
    "                date_diff = (row['next_basket_date'] - large_basket_date).days\n",
    "                if 0 <= date_diff <= max_days and len(actual_basket) <= max_items:\n",
    "                    df.at[index, 'forgotten_item_basket'] = 1\n",
    "                    large_basket_date = None  # Reset large_basket_date\n",
    "                elif date_diff > max_days:\n",
    "                    large_basket_date = None  # Reset large_basket_date if more than max_days have passed\n",
    "    \n",
    "    # Drop the temporary next_basket_date column\n",
    "    df = df.drop(columns=['next_basket_date'])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function fo concatenate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_combine_predictions(model_names, lengths, directories, base_path='..'):\n",
    "    \"\"\"\n",
    "    Load, sort, deduplicate, and combine prediction CSV files for specified models, lengths, and directories.\n",
    "    \n",
    "    Args:\n",
    "    model_names (list): List of model names to include.\n",
    "    lengths (list): List of prediction lengths to include.\n",
    "    directories (list): List of directories to search in (e.g., ['1fE', '1vR']).\n",
    "    base_path (str): Base path for the Experiments folder.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Combined dataframe of all matching predictions.\n",
    "    \"\"\"\n",
    "    combined_df = pd.DataFrame()\n",
    "    \n",
    "    sort_columns = ['dataset_name', 'category_mode', 'split_mode', 'model_name', \n",
    "                    'customer_id', 'pred_length', 'next_basket_number']\n",
    "    \n",
    "    for directory in directories:\n",
    "        for model in model_names:\n",
    "            for split in ['split_10', 'split_20', 'split_30', 'split_40', 'split_50', \n",
    "                          'split_60', 'split_70', 'split_80', 'split_90', 'split_fixed']:\n",
    "                pattern = os.path.join(base_path, 'Experiments', directory, model, split, \n",
    "                                       f'pred_{directory}_*_{model}_*.csv')\n",
    "                for file in glob(pattern):\n",
    "                    # Extract length from filename\n",
    "                    file_length = int(file.split('_')[-1].split('.')[0])\n",
    "                    \n",
    "                    if file_length in lengths:\n",
    "                        df = pd.read_csv(file)\n",
    "                        \n",
    "                        # Ensure all sort columns exist in the DataFrame\n",
    "                        for col in sort_columns:\n",
    "                            if col not in df.columns:\n",
    "                                df[col] = None  # or some appropriate default value\n",
    "                        \n",
    "                        # Sort the DataFrame\n",
    "                        df = df.sort_values(by=sort_columns)\n",
    "                        \n",
    "                        # Remove duplicates based on the sorting columns\n",
    "                        df = df.drop_duplicates(subset=sort_columns, keep='first')\n",
    "                        \n",
    "                        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    \n",
    "    # Final sort and deduplication of the combined DataFrame\n",
    "    combined_df = combined_df.sort_values(by=sort_columns)\n",
    "    combined_df = combined_df.drop_duplicates(subset=sort_columns, keep='first')\n",
    "    \n",
    "    # Save the combined dataframe as a CSV file\n",
    "    output_file = 'combined_predictions_all_directories.csv'\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    print(f\"Combined predictions saved to {output_file}\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Example usage:\n",
    "# models = ['tbp', 'nmf', 'hrm', 'fpmc', 'clf', 'markov', 'ibp']\n",
    "# lengths = list(range(2, 21))  # 2 to 20 inclusive\n",
    "# directories = ['1fE', '1vR']\n",
    "# result_df = load_combine_predictions(models, lengths, directories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
